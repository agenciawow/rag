{
  "evaluation_summary": {
    "total_questions": 12,
    "successful_evaluations": 12,
    "failed_evaluations": 0,
    "success_rate": 1.0,
    "system_type": "OptimizedMultimodalRagSearcher",
    "optimization_approach": "Two-Phase Retrieval"
  },
  "overall_metrics": {
    "average_precision": 0.7916666666666666,
    "average_recall": 0.7916666666666666,
    "average_f1_score": 0.7916666666666666,
    "average_page_accuracy": 0.7777777777777778,
    "average_keyword_coverage": 0.7625,
    "average_response_time": 17.345608055591583,
    "average_phase1_candidates": 6.666666666666667,
    "average_phase2_selected": 0.9166666666666666,
    "average_reduction_ratio": 0.71875
  },
  "category_breakdown": {
    "visual": {
      "count": 1,
      "avg_precision": 1.0,
      "avg_recall": 1.0,
      "avg_f1": 1.0,
      "avg_response_time": 15.111567258834839,
      "avg_phase1_candidates": 8,
      "avg_phase2_selected": 1
    },
    "negative": {
      "count": 1,
      "avg_precision": 1.0,
      "avg_recall": 1.0,
      "avg_f1": 1.0,
      "avg_response_time": 8.01965069770813,
      "avg_phase1_candidates": 0,
      "avg_phase2_selected": 0
    },
    "specific": {
      "count": 3,
      "avg_precision": 1.0,
      "avg_recall": 1.0,
      "avg_f1": 1.0,
      "avg_response_time": 16.82124678293864,
      "avg_phase1_candidates": 8,
      "avg_phase2_selected": 1
    },
    "optimization": {
      "count": 2,
      "avg_precision": 0.25,
      "avg_recall": 0.25,
      "avg_f1": 0.25,
      "avg_response_time": 20.95601534843445,
      "avg_phase1_candidates": 4,
      "avg_phase2_selected": 1
    }
  },
  "pipeline_analysis": {
    "total_phase1_retrievals": 80,
    "total_phase2_selections": 11,
    "models_used": [
      "gpt-4.1"
    ],
    "optimization_methods": [
      "Two-Phase Retrieval"
    ],
    "phase1_efficiency": {
      "max_candidates": 8,
      "min_candidates": 0,
      "std_candidates": 3.113995776646092
    },
    "phase2_efficiency": {
      "max_selected": 2,
      "min_selected": 0,
      "std_selected": 0.5149286505444373
    }
  },
  "detailed_results": [
    {
      "question_id": "tech_001",
      "question": "Quais são os três subgrafos hierárquicos na arquitetura do Zep?",
      "selected_pages": [
        2
      ],
      "expected_pages": [
        2
      ],
      "answer": "A resposta vem do documento '2501', página 2.\n\nOs três subgrafos hierárquicos na arquitetura do Zep são:\n\n1. Subgrafo de Episódio (Episode Subgraph): Este subgrafo contém nós de episódios, que armazenam dados brutos de entrada, como mensagens, textos ou JSON. Os episódios servem como um repositório de dados não destrutivo, a partir do qual entidades semânticas e relações são extraídas. As arestas desse subgrafo conectam episódios às entidades semânticas referenciadas.\n\n2. Subgrafo de Entidade Semântica (Semantic Entity Subgraph): Este subgrafo é construído a partir do subgrafo de episódio. Os nós de entidade representam entidades extraídas dos episódios e resolvidas com entidades já existentes no grafo. As arestas representam relações entre entidades extraídas dos episódios.\n\n3. Subgrafo de Comunidade (Community Subgraph): Este é o nível mais alto do grafo de conhecimento do Zep. Os nós de comunidade representam agrupamentos de entidades fortemente conectadas e contêm sumarizações de alto nível desses agrupamentos, oferecendo uma visão mais abrangente e interconectada da estrutura do subgrafo de entidades. As arestas conectam comunidades aos seus membros (entidades).\n\nPortanto, os três subgrafos hierárquicos são: subgrafo de episódio, subgrafo de entidade semântica e subgrafo de comunidade.",
      "response_time": 19.577849626541138,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 1.0,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 2 apresenta uma explicação direta e detalhada sobre os três subgrafos hierárquicos na arquitetura do Zep: episódio, entidade semântica e comunidade. Ela define cada subgrafo, seu papel e como eles se relacionam, respondendo de forma completa e factual à pergunta. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "tech_002",
      "question": "Como o Graphiti lida com a invalidação de arestas (fatos) no grafo de conhecimento?",
      "selected_pages": [
        3
      ],
      "expected_pages": [
        3
      ],
      "answer": "A resposta à pergunta sobre como o Graphiti lida com a invalidação de arestas (fatos) no grafo de conhecimento está presente no documento '2501', página 3.\n\nO Graphiti gerencia a invalidação de arestas por meio de um processo que envolve extração temporal e comparação semântica. O sistema extrai informações temporais dos fatos a partir do contexto do episódio, registrando quando cada fato foi criado (t_created) e invalidado (t_expired), além de monitorar o intervalo de validade do fato (t_valid e t_invalid). Esses dados temporais são armazenados nas arestas do grafo.\n\nQuando um novo fato (aresta) é introduzido, o sistema utiliza um LLM para comparar essa nova aresta com arestas existentes que sejam semanticamente relacionadas, a fim de identificar possíveis contradições. Se forem encontradas contradições com sobreposição temporal, as arestas afetadas são invalidadas: o sistema define o campo t_invalid da aresta antiga para coincidir com o t_valid da nova aresta que a invalida. Dessa forma, o Graphiti prioriza consistentemente as informações mais recentes ao determinar a invalidação de arestas, mantendo tanto o estado atual das relações quanto o histórico de sua evolução ao longo do tempo.\n\nPortanto, o Graphiti lida com a invalidação de arestas utilizando extração temporal, comparação semântica via LLM e atualização dos campos temporais das arestas para refletir a validade e a invalidação dos fatos, sempre priorizando as informações mais recentes. Esta explicação é baseada exclusivamente no conteúdo da página 3 do documento '2501'.",
      "response_time": 21.14695382118225,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 0.8333333333333334,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 3 traz uma explicação detalhada e direta sobre como o Graphiti lida com a invalidação de arestas (fatos) no grafo de conhecimento. Ela descreve o processo de extração temporal, o rastreamento de validade das arestas, o uso de LLM para identificar contradições temporais e o mecanismo de invalidação ao atualizar os timestamps das arestas afetadas. Essa página responde de forma completa e específica à pergunta, tornando desnecessária a seleção de outras páginas. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "tech_003",
      "question": "Quais são os três métodos de busca implementados pelo Zep para recuperação de memória?",
      "selected_pages": [
        4
      ],
      "expected_pages": [
        5
      ],
      "answer": "A resposta à sua pergunta está presente na página 4 do documento '2501'.\n\nSegundo o documento, o Zep implementa três métodos de busca para recuperação de memória:\n\n1. Busca por similaridade semântica usando cosseno (cosine semantic similarity search, ϕcos)\n2. Busca por texto completo utilizando Okapi BM25 (Okapi BM25 full-text search, ϕbm25)\n3. Busca em largura (breadth-first search, ϕbfs)\n\nEsses métodos são utilizados para identificar nós e arestas candidatas que podem conter informações relevantes para responder a uma consulta. Os dois primeiros métodos utilizam a implementação do Lucene no Neo4j.\n\nPortanto, os três métodos de busca implementados pelo Zep para recuperação de memória são: busca por similaridade semântica (cosseno), busca por texto completo (Okapi BM25) e busca em largura (breadth-first search). Esta resposta foi elaborada exclusivamente com base no conteúdo da página 4 do documento '2501'.",
      "response_time": 13.002659797668457,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "page_accuracy": 0.0,
      "keyword_coverage": 0.6,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 4 apresenta explicitamente os três métodos de busca implementados pelo Zep para recuperação de memória: \"cosine semantic similarity search\", \"Okapi BM25 full-text search\" e \"breadth-first search\". Ela detalha cada método e sua função, respondendo de forma direta e factual à pergunta. Não é necessário consultar outra página, pois a resposta está completa aqui. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "concept_001",
      "question": "Qual é a principal limitação dos frameworks RAG que o Zep visa resolver?",
      "selected_pages": [
        1
      ],
      "expected_pages": [
        1
      ],
      "answer": "A principal limitação dos frameworks RAG que o Zep visa resolver, conforme apresentado no documento '2501', página 1, é o fato de que os frameworks RAG atuais são limitados à recuperação de documentos estáticos. Ou seja, eles trabalham principalmente com corpora de conhecimento amplo e estático, onde o conteúdo dos documentos raramente muda. No entanto, aplicações empresariais exigem integração dinâmica de conhecimento proveniente de diversas fontes, incluindo conversas em andamento e dados de negócios. O Zep aborda essa limitação fundamental ao introduzir um mecanismo central chamado Graphiti, que é um motor de grafo de conhecimento sensível ao tempo. Esse motor sintetiza dinamicamente tanto dados conversacionais não estruturados quanto dados de negócios estruturados, mantendo os relacionamentos históricos. Assim, Zep permite a integração de dados dinâmicos e em evolução, superando a limitação dos RAG tradicionais de lidar apenas com informações estáticas. Esta resposta é baseada exclusivamente no conteúdo da página 1 do documento '2501'.",
      "response_time": 21.11142635345459,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 1.0,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 1 apresenta, de forma direta e factual no resumo (abstract), a principal limitação dos frameworks RAG que o Zep visa resolver: a limitação dos agentes baseados em LLM a recuperações estáticas de documentos, o que é inadequado para aplicações empresariais que exigem integração dinâmica de conhecimento de fontes diversas, como conversas em andamento e dados de negócios. Explica que o Zep resolve essa limitação ao introduzir um grafo de conhecimento temporalmente sensível, capaz de sintetizar dados não estruturados e estruturados mantendo relações históricas. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "concept_002",
      "question": "De que forma a estrutura de memória do Zep se assemelha aos modelos psicológicos da memória humana?",
      "selected_pages": [
        2
      ],
      "expected_pages": [
        2
      ],
      "answer": "A estrutura de memória do Zep se assemelha aos modelos psicológicos da memória humana ao adotar uma abordagem dual, armazenando tanto dados episódicos brutos quanto informações semânticas derivadas. Segundo o documento '2501', página 2, essa arquitetura reflete modelos psicológicos que distinguem entre memória episódica, responsável por representar eventos distintos, e memória semântica, que captura associações entre conceitos e seus significados. No Zep, isso é implementado por meio de subgrafos hierárquicos: o subgrafo de episódios armazena dados brutos de eventos (como mensagens), enquanto o subgrafo de entidades semânticas representa entidades e relações extraídas desses episódios. Além disso, há um subgrafo de comunidades que agrupa entidades relacionadas, oferecendo uma visão mais abrangente e interconectada, semelhante à organização hierárquica da memória humana. Dessa forma, a estrutura de memória do Zep permite que agentes baseados em LLM desenvolvam memórias mais sofisticadas e alinhadas ao funcionamento da memória humana, conforme descrito na página 2 do documento '2501'.",
      "response_time": 17.80141806602478,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 1.0,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 2 descreve diretamente como a estrutura de memória do Zep se inspira e se assemelha aos modelos psicológicos da memória humana, detalhando a separação entre memória episódica e semântica, e explicando como essas estruturas são implementadas no Zep. Ela também discute a hierarquia de subgrafos (episódico, semântico e de comunidade) e faz paralelos explícitos com a memória humana, tornando-a a página mais relevante e suficiente para responder à pergunta. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "specific_001",
      "question": "Qual foi a pontuação de acurácia (Score) do Zep com o modelo gpt-4-turbo na avaliação Deep Memory Retrieval (DMR), conforme a Tabela 1?",
      "selected_pages": [
        6
      ],
      "expected_pages": [
        6
      ],
      "answer": "A pontuação de acurácia (Score) do Zep com o modelo gpt-4-turbo na avaliação Deep Memory Retrieval (DMR), conforme a Tabela 1, foi de 94,8%. Essa informação está claramente apresentada na tabela e também é confirmada no texto da página, que explica que o Zep atingiu 94,8% de acurácia ao utilizar o gpt-4-turbo, superando ligeiramente outros métodos avaliados. Esta resposta foi obtida exclusivamente do documento '2501', página 6.",
      "response_time": 14.259807586669922,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 0.8,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 6 contém a Tabela 1, que apresenta explicitamente a pontuação de acurácia (Score) do Zep com o modelo gpt-4-turbo na avaliação Deep Memory Retrieval (DMR), respondendo de forma direta e factual à pergunta. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "specific_002",
      "question": "Na Tabela 2, qual foi a redução de latência do Zep em comparação com o baseline 'Full-context' usando o modelo gpt-4o?",
      "selected_pages": [
        7
      ],
      "expected_pages": [
        7
      ],
      "answer": "A resposta está presente na página 7 do documento '2501'. Segundo a Tabela 2, ao comparar o modelo gpt-4o usando o baseline 'Full-context' com o Zep, a latência do 'Full-context' foi de 28,9 segundos, enquanto a latência do Zep foi de 2,58 segundos. Portanto, a redução de latência do Zep em relação ao baseline 'Full-context' usando o modelo gpt-4o foi de 26,32 segundos, o que representa uma diminuição de aproximadamente 90% no tempo de resposta. Essa informação é confirmada também no texto abaixo da tabela, que destaca a redução de latência em torno de 90% com o uso do Zep.",
      "response_time": 18.665379285812378,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 0.5,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 7 contém a Tabela 2 (\"LongMemEval\") com os dados de latência para o modelo gpt-4o, tanto para o baseline \"Full-context\" quanto para o Zep. Ela apresenta explicitamente os valores de latência necessários para calcular a redução e discute diretamente a comparação de desempenho entre Zep e o baseline, incluindo a redução percentual de latência. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "specific_003",
      "question": "Qual algoritmo de detecção de comunidade o Zep utiliza e por quê?",
      "selected_pages": [
        4
      ],
      "expected_pages": [
        4
      ],
      "answer": "De acordo com o documento '2501', página 4, o Zep utiliza o algoritmo de propagação de rótulos (label propagation) para detecção de comunidades, em vez do algoritmo Leiden. A escolha pelo label propagation foi motivada pela sua facilidade de extensão dinâmica, o que permite ao sistema manter representações de comunidades precisas por mais tempo à medida que novos dados entram no grafo, adiando a necessidade de atualizações completas das comunidades. O label propagation possibilita que, ao adicionar um novo nó de entidade ao grafo, o sistema avalie as comunidades dos nós vizinhos e atribua o novo nó à comunidade mais comum entre eles, atualizando os resumos e o grafo conforme necessário. Essa estratégia dinâmica reduz significativamente a latência e os custos de inferência de LLM, embora ainda sejam necessárias atualizações periódicas completas para evitar divergências acumuladas. Portanto, o Zep utiliza o algoritmo de propagação de rótulos devido à sua eficiência e capacidade de atualização incremental, conforme descrito na página 4 do documento '2501'.",
      "response_time": 17.538553476333618,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 0.75,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 4 responde de forma direta e detalhada à pergunta, especificando que o Zep utiliza o algoritmo de propagação de rótulos (label propagation) para detecção de comunidades, em vez do Leiden, e explica o motivo dessa escolha (dinamismo e menor custo de atualização). Não é necessário selecionar outra página, pois a resposta é completa e factual. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "visual_001",
      "question": "O que a Tabela 3 detalha sobre os resultados da avaliação LongMemEval?",
      "selected_pages": [
        7
      ],
      "expected_pages": [
        7
      ],
      "answer": "A Tabela 3 detalha a divisão dos resultados da avaliação LongMemEval por tipo de questão, comparando o desempenho do modelo Zep com o modelo full-context, tanto para gpt-4o-mini quanto para gpt-4o. Ela apresenta, para cada tipo de questão (como single-session-preference, single-session-assistant, temporal-reasoning, multi-session, knowledge-update e single-session-user), as porcentagens de acerto dos modelos full-context e Zep, além da diferença percentual (Delta) entre eles.\n\nOs resultados mostram que o Zep supera o modelo full-context em quase todos os tipos de questões, especialmente nas categorias mais complexas, como single-session-preference, temporal-reasoning e multi-session, com ganhos percentuais expressivos. Por exemplo, para gpt-4o, o Zep teve um aumento de 184% em single-session-preference e de 38,4% em temporal-reasoning. Em algumas categorias, como single-session-assistant com gpt-4o, houve uma pequena redução de desempenho. No geral, a tabela evidencia que o Zep traz melhorias significativas, principalmente em questões complexas e quando utilizado com modelos mais avançados.\n\nEsta resposta foi elaborada exclusivamente com base no documento '2501', página 7.",
      "response_time": 15.111567258834839,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 0.6666666666666666,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 1,
      "justification": "A página 7 contém a Tabela 3 (\"LongMemEval, Question Type Breakdown\") e detalha explicitamente os resultados da avaliação LongMemEval, incluindo a performance por tipo de questão, modelos comparados, valores numéricos e análise dos ganhos do Zep em relação ao baseline. A explicação textual logo abaixo da tabela também interpreta os resultados, tornando esta página suficiente para responder à pergunta de forma direta e factual. (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "negative_001",
      "question": "Qual é o custo para licenciar a tecnologia Zep para uso comercial?",
      "selected_pages": [],
      "expected_pages": [],
      "answer": "Nenhuma informação relevante encontrada (confirmado pela verificação de relevância).",
      "response_time": 8.01965069770813,
      "precision": 1.0,
      "recall": 1.0,
      "f1_score": 1.0,
      "page_accuracy": 1.0,
      "keyword_coverage": 1.0,
      "total_candidates": 0,
      "phase1_candidates": 0,
      "phase2_selected": 0,
      "justification": "Verificação de relevância rejeitou os candidatos",
      "model_used": "",
      "optimization_method": "",
      "error": null
    },
    {
      "question_id": "optimization_001",
      "question": "Como o Zep mantém a coerência temporal nos grafos de conhecimento dinâmicos?",
      "selected_pages": [
        2,
        3
      ],
      "expected_pages": [
        3,
        4
      ],
      "answer": "O Zep mantém a coerência temporal em seus grafos de conhecimento dinâmicos por meio de uma combinação de extração temporal detalhada, modelagem bi-temporal e mecanismos de invalidação de arestas, conforme descrito nas páginas 2501 p.2 e 2501 p.3.\n\nNa página 2501 p.2, é explicado que o Zep utiliza o mecanismo do Graphiti, um motor de grafo de conhecimento dinâmico e sensível ao tempo. O grafo armazena não apenas os fatos e relações, mas também seus períodos de validade, permitindo representar um mundo complexo e em constante evolução. O Zep implementa um modelo bi-temporal: a linha do tempo T representa a ordem cronológica dos eventos (quando os fatos realmente ocorreram ou foram válidos), enquanto a linha do tempo T' representa a ordem transacional de ingestão dos dados pelo sistema (quando a informação foi registrada no sistema). Essa abordagem bi-temporal permite ao Zep distinguir entre o momento em que um fato ocorreu e o momento em que foi registrado, o que é fundamental para modelar dados conversacionais dinâmicos e memória de agentes.\n\nNa página 2501 p.3, detalha-se como o sistema extrai informações temporais dos fatos a partir do contexto dos episódios, usando o timestamp de referência t_ref. Isso permite capturar tanto datas absolutas (por exemplo, \"Alan Turing nasceu em 23 de junho de 1912\") quanto relativas (por exemplo, \"comecei meu novo emprego há duas semanas\"). O sistema armazena quatro timestamps para cada fato: t'_created e t'_expired (na linha do tempo transacional T', indicando quando o fato foi criado ou invalidado no sistema) e t_valid e t_invalid (na linha do tempo cronológica T, indicando o intervalo em que o fato foi verdadeiro no mundo modelado). Esses dados temporais são armazenados nas arestas do grafo junto com as demais informações do fato.\n\nAlém disso, quando novas arestas (fatos) são introduzidas, o sistema utiliza um LLM para comparar essas novas informações com arestas já existentes que sejam semanticamente relacionadas, a fim de identificar possíveis contradições temporais. Se forem encontradas contradições com sobreposição temporal, as arestas afetadas são invalidadas ajustando seu t_invalid para coincidir com o t_valid da nova aresta que as invalida. O sistema sempre prioriza a informação mais recente, seguindo a linha do tempo transacional T', ao decidir sobre a invalidação de arestas.\n\nPortanto, a coerência temporal é mantida por: (1) extração e representação explícita de múltiplos tipos de timestamps, (2) distinção entre tempo do mundo e tempo de ingestão, (3) atualização dinâmica e invalidação de fatos contraditórios com rastreamento de períodos de validade, e (4) priorização de informações mais recentes em caso de conflito. Todas essas informações estão presentes nas páginas 2501 p.2 e 2501 p.3. Se houver detalhes adicionais sobre mecanismos internos ou algoritmos específicos, eles não estão presentes nestas páginas.",
      "response_time": 29.11418843269348,
      "precision": 0.5,
      "recall": 0.5,
      "f1_score": 0.5,
      "page_accuracy": 0.3333333333333333,
      "keyword_coverage": 1.0,
      "total_candidates": 8,
      "phase1_candidates": 8,
      "phase2_selected": 2,
      "justification": " (Confidence: Alta)",
      "model_used": "gpt-4.1",
      "optimization_method": "Two-Phase Retrieval",
      "error": null
    },
    {
      "question_id": "optimization_002",
      "question": "Quais são as vantagens do uso de embeddings multimodais no Zep comparado a embeddings apenas textuais?",
      "selected_pages": [],
      "expected_pages": [
        2,
        5
      ],
      "answer": "Nenhuma informação relevante encontrada (confirmado pela verificação de relevância).",
      "response_time": 12.797842264175415,
      "precision": 0.0,
      "recall": 0.0,
      "f1_score": 0.0,
      "page_accuracy": 0.0,
      "keyword_coverage": 0.0,
      "total_candidates": 0,
      "phase1_candidates": 0,
      "phase2_selected": 0,
      "justification": "Verificação de relevância rejeitou os candidatos",
      "model_used": "",
      "optimization_method": "",
      "error": null
    }
  ],
  "evaluation_timestamp": "2025-06-13T04:14:48.090366"
}